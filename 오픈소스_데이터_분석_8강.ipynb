{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/attackmood/Data-Analysis-with-Open-Source/blob/main/%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D_8%EA%B0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ-_K7V9snHK"
      },
      "source": [
        "# 오픈소스 기반 데이터 분석 8강"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 분석 방법론"
      ],
      "metadata": {
        "id": "xy-q5BlU48cP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iUhflCxPcH0"
      },
      "source": [
        "## 8-1 통계적 모형을 활용한 분석 (statsmodels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vsS87Vx9dV6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "891e86db-7670-431d-d46e-0c8f9e6ba5c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.977\n",
            "Model:                            OLS   Adj. R-squared:                  0.975\n",
            "Method:                 Least Squares   F-statistic:                     345.0\n",
            "Date:                Fri, 19 Dec 2025   Prob (F-statistic):           7.28e-08\n",
            "Time:                        06:43:57   Log-Likelihood:                -12.020\n",
            "No. Observations:                  10   AIC:                             28.04\n",
            "Df Residuals:                       8   BIC:                             28.65\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept      1.7622      0.615      2.866      0.021       0.344       3.180\n",
            "X              1.8406      0.099     18.574      0.000       1.612       2.069\n",
            "==============================================================================\n",
            "Omnibus:                        5.058   Durbin-Watson:                   1.207\n",
            "Prob(Omnibus):                  0.080   Jarque-Bera (JB):                1.191\n",
            "Skew:                          -0.012   Prob(JB):                        0.551\n",
            "Kurtosis:                       1.309   Cond. No.                         13.7\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "# statsmodels의 formula api 임포트\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "## 난수 시드 설정\n",
        "random.seed(1)\n",
        "\n",
        "## 데이터 생성\n",
        "X = list(range(1, 11))\n",
        "y = [2*x + 1 + random.gauss(0, 1) for x in X] # x의 값에 가우시안값을 적용해서 y값을 만듦\n",
        "\n",
        "## 데이터프레임 생성\n",
        "data = pd.DataFrame({'X': X, 'y': y})\n",
        "\n",
        "## OLS(최소 제곱법) 회귀 모델 생성 및 학습: 잔차의 제곱의 합이 가장 작은 선을 찾음\n",
        "## 'y'를 종속 변수로 하고 다른 특성(X)을 독립 변수로 사용\n",
        "model = smf.ols(formula='y~ X', data=data).fit()\n",
        "# 'y ~ X'는 R 스타일의 모델 공식. \"y는 X에 의해 설명된다\"\n",
        "\n",
        "## 모델 요약 결과 출력\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "# model.summary()가 보여주는 주요 지표들:\n",
        "\n",
        "# R-squared: 모델이 데이터의 변동을 얼마나 설명하는지 (0~1 사이). 1에 가까울수록 좋다\n",
        "# Coefficients: 추정된 절편(Intercept)과 기울기(X의 계수)\n",
        "# p-value: 해당 변수가 통계적으로 유의미한지 판단 (보통 0.05 미만이면 유의미)\n",
        "# Standard Error: 추정값의 불확실성 정도"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEYBAflNPcH6"
      },
      "source": [
        "## 8-2 기계학습을 활용한 분석 (scikit-learn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ptis5NADdZbj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb9eefeb-f025-45e3-b08e-82b350b30273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9707602339181286\n"
          ]
        }
      ],
      "source": [
        "# scikit-learn의 앙상블(ensemble) 알고리즘 중 RandomForestClassifier 임포트\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# 모델 평가를 위한 데이터 분할(split) 함수 임포트\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 모델의 정확도(accuracy)를 측정하는 함수 임포트\n",
        "from sklearn.metrics import accuracy_score\n",
        "# 예제 데이터셋(유방암 데이터) 로드 함수 임포트\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "\n",
        "## 데이터 로드 및 분할\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "## 학습/테스트 데이터셋 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "## 랜덤 포레스트 모델 생성 및 학습\n",
        "model = RandomForestClassifier(n_estimators=100) # 100개의 서로 다른 트리를 만듦 -> 각 트리가 독립적으로 예측 -> 다수결로 최종 결정\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "## 예측 및 정확도 평가\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)\n",
        "\n",
        "# 각각의 환자들에 대해 cancer가 있는지 없는지 정확도 측정\n",
        "# 랜덤포레스트: 예측할 때 복수의 사람들한테 물어봐서 정확도를 예측한다?\n",
        "# 100개의 결정 트리(decision tree)를 만듭니다 (n_estimators=100)\n",
        "# 각 트리는 데이터의 일부만 보고 학습합니다\n",
        "# 예측할 때 100개 트리가 투표합니다\n",
        "\n",
        "# 트리1: 악성, 트리2: 양성, 트리3: 악성, ...\n",
        "# 과반수가 선택한 것이 최종 예측\n",
        "\n",
        "# 앙상블 학습\n",
        "# - 각 트리가 다른 실수를 하면, 다수결로 오류를 상쇄\n",
        "# - 과적합(overfitting)을 방지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WvneUhOPcH9"
      },
      "source": [
        "## 8-3 딥러닝을 활용한 분석 (tensorflow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ze_9DpFddcTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c328c27a-359e-4b8a-9e3d-1b6a1441fef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Epoch 1/3\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 30ms/step - accuracy: 0.6917 - loss: 0.9039 - val_accuracy: 0.8050 - val_loss: 0.5641\n",
            "Epoch 2/3\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8209 - loss: 0.5139 - val_accuracy: 0.8208 - val_loss: 0.5177\n",
            "Epoch 3/3\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.8375 - loss: 0.4729 - val_accuracy: 0.8208 - val_loss: 0.5254\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step\n",
            "\n",
            "Test Accuracy: 0.8180000185966492\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.83      1000\n",
            "           1       0.94      0.87      0.91      1000\n",
            "           2       0.81      0.72      0.76      1000\n",
            "           3       0.77      0.59      0.67      1000\n",
            "           4       0.74      0.80      0.77      1000\n",
            "           5       0.68      0.84      0.75      1000\n",
            "           6       0.89      0.84      0.87      1000\n",
            "           7       0.80      0.88      0.84      1000\n",
            "           8       0.94      0.82      0.88      1000\n",
            "           9       0.86      0.95      0.90      1000\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# 딥러닝 분석을 위한 tensorflow 임포트\n",
        "import tensorflow as tf\n",
        "\n",
        "## CIFAR-10 데이터셋 로드 및 전처리(이미지 분류 문제)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "\n",
        "## MobileNetV2 기반 모델 구축\n",
        "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(160, 160, 3)) # 전이학습\n",
        "base_model.trainable = False # 사전 학습된 부분은 **동결(freeze)**해서 가중치를 바꾸지 않음\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Resizing(160, 160),         # 1. 이미지 크기 조정\n",
        "    base_model,                                 # 2. 특성 추출기: 이미지에서 의미있는 패턴 추출\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),   # 3. 차원 축소: 추출된 특성맵을 1차원 벡터로 압축\n",
        "    tf.keras.layers.Dense(10)                   # 4. 분류기: 10개 클래스에 대한 점수 출력\n",
        "])\n",
        "\n",
        "## 모델 컴파일\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "## 모델 학습\n",
        "model.fit(x_train, y_train, epochs=3, validation_split=0.2)\n",
        "\n",
        "## 예측 및 성능 평가\n",
        "y_pred = tf.argmax(model.predict(x_test), axis=1)\n",
        "print(\"\\nTest Accuracy:\", model.evaluate(x_test, y_test, verbose=0)[1])\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNB7tpokPcH_"
      },
      "source": [
        "## 8-4 EDA 예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhF8O0CkdgwC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "## 당뇨병 데이터셋 로드 및 데이터프레임 생성\n",
        "diabetes = load_diabetes()\n",
        "df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
        "df['target'] = diabetes.target\n",
        "\n",
        "## dataframe의 describe를 이용하여 기본 통계량 출력\n",
        "\n",
        "## 상관 행렬 시각화\n",
        "plt.figure(figsize=(12,8))\n",
        "# dataframe의 각 열(변수)들 간의 상관 계수(correlation coefficient)를 계산하고 corr_matrix로 저장\n",
        "# seaborn으로 corr_matrix를 heatmap으로 시각화\n",
        "plt.title('Diabetes Dataset Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuoWU4FFPcIA"
      },
      "source": [
        "## 8-5 기술통계량 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLSGHj3ddkWf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "## 아이리스 데이터셋 로드\n",
        "df = sns.load_dataset('iris')\n",
        "\n",
        "# 기술 통계량\n",
        "print(\"=== 기본 통계량 ===\")\n",
        "print(df.describe())\n",
        "\n",
        "# 데이터 미리보기\n",
        "print(\"\\n=== 데이터 미리보기 ===\")\n",
        "\n",
        "# 그룹별 통계정보\n",
        "print(\"\\n=== 품종별 평균값 ===\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFOLMIFtPcID"
      },
      "source": [
        "## 8-6 데이터 시각화 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6b3cp7UPcID"
      },
      "outputs": [],
      "source": [
        "# 한글 처리를 위한 matplotlib 설정 (1)\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache –fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGWiB2Z-PcIE"
      },
      "source": [
        "- 리소스 재시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV1HYIOBPcIE"
      },
      "outputs": [],
      "source": [
        "# 한글 처리를 위한 matplotlib 설정 (2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekh3vzrsdrBd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "## 아이리스 데이터셋 로드\n",
        "df = sns.load_dataset('iris')\n",
        "\n",
        "## 서브플롯 설정\n",
        "plt.figure(figsize=(9, 12))\n",
        "plt.suptitle('Iris 데이터셋 시각화', y=1.02, fontsize=14)\n",
        "\n",
        "## 첫 번째 서브플롯: 꽃잎 길이 분포 (히스토그램)\n",
        "plt.subplot(4, 1, 1)\n",
        "# seaborn을 이용하여 petal_length를 10개 구간으로 나누어 히스토그램 표시\n",
        "plt.title('꽃잎 길이 분포')\n",
        "plt.xlabel('꽃잎 길이 (cm)')\n",
        "\n",
        "## 두 번째 서브플롯: 꽃잎 길이 vs 너비 (산점도)\n",
        "plt.subplot(4, 1, 2)\n",
        "species_list = df['species'].unique()\n",
        "colors = {'setosa':'red', 'versicolor':'green', 'virginica':'blue'}\n",
        "\n",
        "for species in species_list:\n",
        "    species_data = df[df['species'] == species]\n",
        "    # matplotlib를 이용하여 길이, 넓이를 산점도로 표시\n",
        "plt.title('꽃잎 길이 vs 너비')\n",
        "plt.xlabel('꽃잎 길이 (cm)')\n",
        "plt.ylabel('꽃잎 너비 (cm)')\n",
        "plt.legend()\n",
        "\n",
        "## 세 번째 서브플롯: 품종별 꽃받침 길이 (박스플롯)\n",
        "plt.subplot(4, 1, 3)\n",
        "# seaborn을 이용하여 품종 별 꽃받침 길이를 박스플롯으로 표시\n",
        "plt.title('품종별 꽃받침 길이 비교')\n",
        "plt.xlabel('품종')\n",
        "plt.ylabel('꽃받침 길이 (cm)')\n",
        "\n",
        "## 네 번째 서브플롯: 숫자형 특성 간 상관관계 (히트맵)\n",
        "plt.subplot(4, 1, 4)\n",
        "numeric_df = df.select_dtypes(include='number')\n",
        "corr = numeric_df.corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('숫자형 특성 간 상관관계')\n",
        "\n",
        "## 레이아웃 조정 및 그래프 표시\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H7M1jS8PcIF"
      },
      "source": [
        "## 8-7 자동화된 EDA 도구"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ydata_profiling"
      ],
      "metadata": {
        "id": "HxhXsvwlQp9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXR2-oPkdrmN"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "## 아이리스 데이터셋 로드\n",
        "df = sns.load_dataset('iris')\n",
        "\n",
        "## 데이터 프로파일링 보고서 생성\n",
        "\n",
        "## HTML 파일로 보고서 저장\n",
        "\n",
        "## 보고서 표시 (Jupyter Notebook 환경에서 보고서가 바로 표시됨)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}